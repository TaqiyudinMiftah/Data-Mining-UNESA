{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5edcdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (4.57.0.dev0)\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.21-py3-none-any.whl.metadata (62 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: torch in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from timm) (2.6.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from timm) (0.23.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: networkx in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from torch->timm) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Collecting torch (from timm)\n",
      "  Using cached torch-2.8.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\taqiy\\anaconda3\\lib\\site-packages (from torchvision->timm) (11.3.0)\n",
      "Collecting sympy>=1.13.3 (from torch->timm)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading timm-1.0.21-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 9.7 MB/s  0:00:00\n",
      "Using cached torch-2.8.0-cp312-cp312-win_amd64.whl (241.3 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: sympy, torch, timm\n",
      "\n",
      "  Attempting uninstall: sympy\n",
      "\n",
      "    Found existing installation: sympy 1.13.1\n",
      "\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "    Uninstalling sympy-1.13.1:\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "  Attempting uninstall: torch\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "    Found existing installation: torch 2.6.0+cpu\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "    Uninstalling torch-2.6.0+cpu:\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "      Successfully uninstalled torch-2.6.0+cpu\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [timm]\n",
      "   ---------------------------------------- 3/3 [timm]\n",
      "\n",
      "Successfully installed sympy-1.14.0 timm-1.0.21 torch-2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unsloth-zoo 2025.10.1 requires transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3, but you have transformers 4.57.0.dev0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers timm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4caa0ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menggunakan device: cpu\n",
      "Dataset dimuat. Ditemukan 3650 gambar.\n",
      "Ditemukan 15 kelas: ['Ayam Bakar', 'Ayam Betutu', 'Ayam Goreng', 'Ayam Pop', 'Bakso', 'Coto Makassar', 'Gado Gado', 'Gudeg', 'Nasi Goreng', 'Pempek', 'Rawon', 'Rendang', 'Sate Madura', 'Sate Padang', 'Soto']\n",
      "Total data: 3650\n",
      "Data latih: 2920\n",
      "Data validasi: 730\n",
      "\n",
      "--- Memulai Pelatihan Tahap 1 (Feature Extraction) ---\n",
      "Tahap 1 Selesai.\n",
      "\n",
      "--- Memulai Pelatihan Tahap 2 (Fine-Tuning) ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 139\u001b[0m\n\u001b[0;32m    137\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m    138\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m--> 139\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    140\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    142\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\taqiy\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    649\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\taqiy\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m _engine_run_backward(\n\u001b[0;32m    355\u001b[0m     tensors,\n\u001b[0;32m    356\u001b[0m     grad_tensors_,\n\u001b[0;32m    357\u001b[0m     retain_graph,\n\u001b[0;32m    358\u001b[0m     create_graph,\n\u001b[0;32m    359\u001b[0m     inputs_tuple,\n\u001b[0;32m    360\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    361\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    362\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\taqiy\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    830\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    831\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder # <-- Import ini\n",
    "\n",
    "# --- 1. Konfigurasi dan Hiperparameter ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Menggunakan device: {DEVICE}\")\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "# NUM_CLASSES akan kita dapatkan secara otomatis dari folder\n",
    "# ... (Hiperparameter lainnya sama) ...\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_FEATURE_EXTRACTION = 3\n",
    "EPOCHS_FINE_TUNING = 5\n",
    "LR_FEATURE_EXTRACTION = 1e-3\n",
    "LR_FINE_TUNING = 1e-5\n",
    "\n",
    "# --- 2. Memuat Data Anda Menggunakan ImageFolder ---\n",
    "\n",
    "# Tentukan path ke data Anda\n",
    "DATA_DIR = './train_with_label' # <-- Ganti dengan path Anda\n",
    "\n",
    "# Transformasi tetap sama (ViT butuh 224x224 dan normalisasi ImageNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Muat dataset menggunakan ImageFolder\n",
    "# Asumsi: Anda belum punya folder validasi terpisah. Kita akan bagi nanti.\n",
    "full_dataset = ImageFolder(root=DATA_DIR, transform=transform)\n",
    "print(f\"Dataset dimuat. Ditemukan {len(full_dataset)} gambar.\")\n",
    "\n",
    "# Dapatkan nama kelas dan jumlah kelas secara otomatis\n",
    "class_names = full_dataset.classes\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"Ditemukan {NUM_CLASSES} kelas: {class_names}\")\n",
    "\n",
    "# --- CATATAN PENTING: Anda perlu membagi data latih dan validasi ---\n",
    "# Kode 'train_with_label' Anda menyiratkan itu semua data latih.\n",
    "# Kita perlu membaginya, misal 80% latih, 20% validasi.\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Total data: {len(full_dataset)}\")\n",
    "print(f\"Data latih: {len(train_dataset)}\")\n",
    "print(f\"Data validasi: {len(val_dataset)}\")\n",
    "\n",
    "# Buat DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "# Kita ganti 'test_loader' menjadi 'val_loader' (loader validasi)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# --- 3. Memuat Model Pre-trained ViT ---\n",
    "\n",
    "# Muat model ViT-B/16 pre-trained\n",
    "# (menggunakan API weights yang modern)\n",
    "model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# --- 4. Tahap 1: Feature Extraction (Melatih Head Saja) ---\n",
    "\n",
    "print(\"\\n--- Memulai Pelatihan Tahap 1 (Feature Extraction) ---\")\n",
    "\n",
    "# Bekukan semua parameter di base model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Ganti classifier head\n",
    "# 'model.heads.head' adalah layer Linear(in_features=768, out_features=1000)\n",
    "in_features = model.heads.head.in_features\n",
    "model.heads.head = nn.Linear(in_features, NUM_CLASSES)\n",
    "\n",
    "# Pindahkan model ke device\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Tentukan loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer HANYA untuk parameter head yang baru (yang 'requires_grad=True')\n",
    "# model.heads.head.parameters() adalah satu-satunya yang tidak dibekukan\n",
    "optimizer = optim.Adam(model.heads.head.parameters(), lr=LR_FEATURE_EXTRACTION)\n",
    "\n",
    "# Loop pelatihan sederhana\n",
    "for epoch in range(EPOCHS_FEATURE_EXTRACTION):\n",
    "    model.train() # Set model ke mode training\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        # Nol-kan gradien\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass dan optimasi\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0: # Cetak setiap 100 batch\n",
    "            print(f'[Epoch {epoch + 1}/{EPOCHS_FEATURE_EXTRACTION}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Tahap 1 Selesai.')\n",
    "\n",
    "# --- 5. Tahap 2: Fine-Tuning (Melatih Seluruh Model) ---\n",
    "\n",
    "print(\"\\n--- Memulai Pelatihan Tahap 2 (Fine-Tuning) ---\")\n",
    "\n",
    "# Buka (unfreeze) semua parameter\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Buat optimizer baru untuk SEMUA parameter dengan learning rate SANGAT KECIL\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR_FINE_TUNING)\n",
    "\n",
    "# Lanjutkan pelatihan\n",
    "for epoch in range(EPOCHS_FINE_TUNING):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'[Epoch {epoch + 1}/{EPOCHS_FINE_TUNING}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Tahap 2 Selesai.')\n",
    "\n",
    "# --- 6. Evaluasi Model ---\n",
    "print(\"\\n--- Evaluasi Model Final ---\")\n",
    "model.eval() # Set model ke mode evaluasi\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # Tidak perlu menghitung gradien saat evaluasi\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Ambil prediksi (kelas dengan probabilitas tertinggi)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Akurasi pada 10000 gambar tes: {accuracy:.2f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
